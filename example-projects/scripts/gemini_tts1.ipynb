{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini TTS on Vertex AI: From Credentials to Crystal-Clear Audio\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Welcome to the exciting world of **Gemini-TTS**, Google’s cutting-edge speech synthesis stack that redefines what’s possible with text-to-speech (TTS) technology. If you’ve worked with Google TTS before, you’re already familiar with its natural-sounding voices powered by neural acoustic models. But **Gemini-TTS** takes things further, offering **granular control over prosody, pacing, and multi-speaker scenes**—all through intuitive, text-based prompts.\n",
    "\n",
    "With Gemini-TTS, you can use **natural-language instructions** (e.g., “speak softly with a smile”), **SSML markup**, and even **cross-lingual prompts** to create everything from short UI affordances to hour-long audiobooks—all in one API call. Whether you’re building conversational agents, narrating audiobooks, or prototyping sonic branding.\n",
    "\n",
    "In this article, we’ll explore the **SDK setup**, **authentication flow**, and **audio configuration options** you need to integrate Gemini-TTS into your pipeline. By the end, you’ll have a clear roadmap for deploying Gemini-TTS, from setting up credentials to generating expressive, high-quality audio. \n",
    "\n",
    "\n",
    "# Prerequisites, Authentication, and Client Bootstrap\n",
    "\n",
    "## Install the SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-genai google-cloud-texttospeech python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Enable the APIs on Google Cloud Console\n",
    "\n",
    "Make sure the following APIs are enabled in your Google Cloud project:\n",
    "\n",
    "- Vertex AI API\n",
    "- Generative Language (Gemini) API\n",
    "- Cloud Text-to-Speech API (ensures consistent quota/accounting for Gemini-TTS voices)\n",
    "\n",
    "## Create a Service Account\n",
    "\n",
    "Create a service account with the following roles:\n",
    "\n",
    "- Vertex AI User\n",
    "- Service Usage Consumer\n",
    "- Download the JSON key for the service account.\n",
    "\n",
    "\n",
    "\n",
    "## Wire Up Environment Variables\n",
    "\n",
    "et up the environment variables to authenticate your application . Add these variables to the .env file in the project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GOOGLE_APPLICATION_CREDENTIALS=\"$PWD/genai/credentials/gemini-tts.json\"\n",
    "GOOGLE_CLOUD_PROJECT=\"my-gemini-project\"\n",
    "GCP_REGION=\"us-central1\"    # Speech models currently deploy in us-central1 & us-east5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Authentication\n",
    "\n",
    "With the prerequisites in place, use the following Python snippet to authenticate the Gemini client with your service account credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import texttospeech_v1beta1 as texttospeech\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def initialize_gemini_client():\n",
    "    \"\"\"\n",
    "    Authenticate and initialize the Gemini Text-to-Speech client.\n",
    "\n",
    "    Returns:\n",
    "        client: The TextToSpeechClient instance.\n",
    "        project: The Google Cloud project ID.\n",
    "        region: The Google Cloud region.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "\n",
    "    # Project metadata pulled from environment\n",
    "    project = str(os.environ.get(\"GCP_PROJECT\"))\n",
    "    region = str(os.environ.get(\"GCP_REGION\"))\n",
    "\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"],\n",
    "        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    "    )\n",
    "\n",
    "    # Gemini TTS currently exposes a global endpoint, but keep it configurable for future regions\n",
    "    tts_location = \"global\"\n",
    "    api_endpoint = (\n",
    "        f\"{tts_location}-texttospeech.googleapis.com\"\n",
    "        if tts_location != \"global\"\n",
    "        else \"texttospeech.googleapis.com\"\n",
    "    )\n",
    "\n",
    "    # Build the low-level Text-to-Speech client\n",
    "    client = texttospeech.TextToSpeechClient(\n",
    "        client_options=ClientOptions(api_endpoint=api_endpoint),\n",
    "        credentials=creds\n",
    "    )\n",
    "\n",
    "    return client, project, region\n",
    "\n",
    "# Initialize the client\n",
    "client, GCP_PROJECT, GCP_REGION = initialize_gemini_client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, Voice, and Language Configuration\n",
    "\n",
    "Gemini-TTS offers a range of models to suit different workloads:\n",
    "\n",
    "- gemini-2.5-flash-tts: Low latency with balanced cost. Ideal for real-time assistants, iterative copy reviews, and UI hints.\n",
    "- gemini-2.5-flash-lite-preview-tts: Lower cost, single-speaker only. Great for background batch jobs or QA passes.\n",
    "- gemini-2.5-pro-tts: Highest fidelity and control. Perfect for long-form narration, IVR personalization, podcasts, or audiobook mastering.\n",
    "\n",
    "## Voice catalog\n",
    "\n",
    "Gemini-TTS provides a diverse voice catalog, with each voice designed to be **language-flexible**. This means a single voice can synthesize multiple locales, enabling consistent narrator identities across multilingual applications. Explore the full list of voices [here](https://docs.cloud.google.com/text-to-speech/docs/gemini-tts#voice_options).\n",
    "\n",
    "## Language support\n",
    "\n",
    "Gemini-TTS supports a wide range of languages. Check the [language matrix](https://docs.cloud.google.com/text-to-speech/docs/gemini-tts#available_languages) for details on ISO codes, voice coverage, and recommended sampling rates.\n",
    "\n",
    "## Programmatic Configuration\n",
    "\n",
    "Here’s how to configure the model, voice, and language programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.5-flash-tts\"\n",
    "VOICE = \"Aoede\"\n",
    "LANGUAGE_CODE = \"en-US\"\n",
    "\n",
    "voice = texttospeech.VoiceSelectionParams(\n",
    "    name=VOICE,\n",
    "    language_code=LANGUAGE_CODE,\n",
    "    model_name=MODEL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Gemini: First Synthesis + Voice Options\n",
    "\n",
    "For single speaker synchronous audio generation a function is defined \n",
    "\n",
    "```python\n",
    "def generate_tts_audio(client, voice, text, prompt, audio_format=\"mp3\", output_file=\"output\"):\n",
    "    \"\"\"\n",
    "    Generate TTS audio using Google Cloud Text-to-Speech API.\n",
    "\n",
    "    Args:\n",
    "        client: The TextToSpeechClient instance.\n",
    "        voice: VoiceSelectionParams object specifying the voice parameters.\n",
    "        text: The text to be converted to speech.\n",
    "        prompt: The prompt to guide the tone and emotion of the speech.\n",
    "        audio_format: The desired audio format (e.g., \"mp3\", \"wav\").\n",
    "        output_file: The base file path to save the generated audio.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging,time\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def generate_tts_audio(client, voice, text, prompt, audio_format=\"mp3\", output_file=\"output\"):\n",
    "    \"\"\"\n",
    "    Generate TTS audio using Google Cloud Text-to-Speech API.\n",
    "\n",
    "    Args:\n",
    "        client: The TextToSpeechClient instance.\n",
    "        voice: VoiceSelectionParams object specifying the voice parameters.\n",
    "        text: The text to be converted to speech.\n",
    "        prompt: The prompt to guide the tone and emotion of the speech.\n",
    "        audio_format: The desired audio format (e.g., \"mp3\", \"wav\").\n",
    "        output_file: The base file path to save the generated audio.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting TTS generation...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Map audio format to the corresponding encoding\n",
    "    audio_encoding_map = {\n",
    "        \"mp3\": texttospeech.AudioEncoding.MP3,\n",
    "        \"wav\": texttospeech.AudioEncoding.LINEAR16,\n",
    "        \"ogg\": texttospeech.AudioEncoding.OGG_OPUS,\n",
    "        \"mulaw\": texttospeech.AudioEncoding.MULAW,\n",
    "        \"alaw\": texttospeech.AudioEncoding.ALAW,\n",
    "        \"linear\": texttospeech.AudioEncoding.PCM,\n",
    "        \"m4a\": texttospeech.AudioEncoding.M4A,\n",
    "    }\n",
    "\n",
    "    if audio_format not in audio_encoding_map:\n",
    "        raise ValueError(f\"Unsupported audio format: {audio_format}\")\n",
    "\n",
    "    # Perform the text-to-speech request\n",
    "    response = client.synthesize_speech(\n",
    "        input=texttospeech.SynthesisInput(text=text, prompt=prompt),\n",
    "        voice=voice,\n",
    "        audio_config=texttospeech.AudioConfig(audio_encoding=audio_encoding_map[audio_format]),\n",
    "    )\n",
    "\n",
    "    # Append the appropriate extension to the output file\n",
    "    output_file_with_extension = f\"{output_file}.{audio_format}\"\n",
    "\n",
    "    # Save the generated audio to a file\n",
    "    with open(output_file_with_extension, \"wb\") as audio_file:\n",
    "        audio_file.write(response.audio_content)\n",
    "\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"TTS generation completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    return output_file_with_extension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT = \"You are having a conversation with a friend. Say the following in a sad and casual way.\"\n",
    "TEXT = \"Hahaha, I did NOT expect that. [coughs] Can you believe it!\"\n",
    "file1 = generate_tts_audio(client, voice, TEXT, PROMPT, audio_format=\"mp3\", output_file=\"gemini1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-language workflows dynamically set `LANGUAGE_CODE` per request while keeping `VOICE` constant. The service will attempt cross-lingual synthesis so your assistant keeps the same vocal character even when switching languages mid-dialog.\n",
    "\n",
    "In the below code example only the language code is changed along with the sytle and text prompt . But the voice is kept the same . The output file generated is `gemini2.mp3`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LANGUAGE_CODE = \"hi-in\"  \n",
    "voice = texttospeech.VoiceSelectionParams(\n",
    "    name=VOICE, language_code=LANGUAGE_CODE, model_name=MODEL\n",
    ")\n",
    "\n",
    "\n",
    "PROMPT = \"आप अपने दोस्त के साथ बातचीत कर रहे हैं। निम्नलिखित को उदास और अनौपचारिक तरीके से कहें।\"\n",
    "TEXT = \"हाहाहा, मैंने इसकी उम्मीद नहीं की थी। [खांसता है] क्या आप इसे मान सकते हैं!\"\n",
    "file2=generate_tts_audio(client, voice, TEXT, PROMPT, audio_format=\"mp3\",output_file=\"gemini2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supported Output Formats\n",
    "\n",
    "Gemini supports the following popular audio formats. Each bullet notes how aggressively the format compresses audio and the relative CPU cost to encode/decode (useful when targeting constrained devices or real-time streaming):\n",
    "\n",
    "- **`LINEAR16` (`audio/L16`)** – raw 16‑bit PCM sampled at 8 kHz – 48 kHz. Compression: none (lossless). CPU: trivial for both encoding and decoding because it’s just byte streaming. Ideal for analytics pipelines, post-production mastering, or when you plan to transcode downstream.\n",
    "\n",
    "- **`MP3` (`audio/mpeg`)** – MPEG layer III with automatic bitrate selection. Compression: lossy psychoacoustic, typically 5–12× smaller than PCM. CPU: encoding is moderate, decoding is low thanks to hardware acceleration on phones and browsers. Best for distribution to consumer devices.\n",
    "\n",
    "- **`OGG_OPUS` (`audio/ogg;codecs=opus`)** – Opus frames inside an OGG container. Compression: aggressive yet high quality at low bitrates (10–20× smaller than PCM). CPU: moderate for encoding/decoding due to LPC + MDCT steps, still comfortable on mobile hardware. Great for chat widgets or RTC-style streaming.\n",
    "\n",
    "## Opus vs MP3: Advantages and Disadvantages\n",
    "\n",
    "- **Audio Quality**: Opus generally delivers higher quality audio than MP3 at the same or lower bitrates, especially for speech and real-time applications.\n",
    "- **Latency**: Opus is optimized for low-latency streaming, making it ideal for interactive use cases like voice chat or conferencing. MP3 is designed for file-based playback and is less suitable for real-time scenarios.\n",
    "- **Bitrate Flexibility**: Opus supports a wide range of bitrates (6 kbps to 510 kbps) and adapts dynamically, while MP3 is more rigid and less efficient at very low bitrates.\n",
    "- **Compression Efficiency**: Opus achieves better compression, resulting in smaller files with comparable or better quality than MP3.\n",
    "- **Compatibility**: MP3 is universally supported across devices and platforms. Opus support is growing but may require additional libraries or codecs on older systems.\n",
    "- **Licensing**: Opus is royalty-free and open source. MP3 was historically patent-encumbered, though most patents have expired.\n",
    "\n",
    "**Summary**: Use Opus for modern, low-latency, high-quality streaming or chat applications. Use MP3 for maximum compatibility with legacy devices and broad distribution.\n",
    "\n",
    "The full list of audio formats can be found at https://docs.cloud.google.com/python/docs/reference/texttospeech/latest/google.cloud.texttospeech_v1.types.AudioEncoding.html. Gemini returns inline audio bytes plus a MIME string describing the format. You can guide that response with `speech_config.audio_config` to match the needs of your delivery channel (streaming, archival, telephony, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"You are having a conversation with a friend. Say the following in a sad and casual way\"\n",
    "TEXT = \"hahaha, i did NOT expect that.[coughs] can you believe it!\"\n",
    "file1=generate_tts_audio(client, voice, TEXT, PROMPT, audio_format=\"ogg\",output_file=\"gemini4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"You are having a conversation with a friend. Say the following in a sad and casual way\"\n",
    "TEXT = \"hahaha, i did NOT expect that.[coughs] can you believe it!\"\n",
    "file1=generate_tts_audio(client, voice, TEXT, PROMPT, audio_format=\"mp3\",output_file=\"gemini4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you omit `audio_config`, Gemini defaults to a lossless PCM payload (`audio/L16;rate=24000`). \n",
    "\n",
    "# Modalities Of Control\n",
    "\n",
    "All of models provide additional modalities of control\n",
    "\n",
    "- Style control: Using natural language prompts, you can adapt the delivery within the conversation by steering it to adopt specific accents and produce a range of tones and expressions including a whisper. Use the global prompt to anchor the vibe and let Gemini carry that tone across an entire utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"Tell the story as an enthusiastic tour guide.\"\n",
    "TEXT = (\n",
    "    \" We arrived at the plaza just as the bells rang. \"\n",
    "    \"to a hushed Spanish accent] Escucha, the city whispers its secrets at dusk. \"\n",
    "    \" Then everyone burst into applause!\"\n",
    ")\n",
    "file_style = generate_tts_audio(client, voice, TEXT, PROMPT, audio_format=\"mp3\", output_file=\"gemini51\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Style prompts can control Emotion , Tone , Pacing ,Clarity, Age , Domain style\n",
    "\n",
    "- Dynamic performance: These models can bring text to life for expressive readings of poetry, newscasts, and engaging storytelling. Layer inline directions directly in the text to momentarily override the global tone with specific emotions or accents. You can direct the model’s delivery style with simple commands for tone, non-speech sounds, and even pacing like Shouting,Whispering,Laughing,Sighing,Clears throat\n",
    "\n",
    "- Enhanced pace and pronunciation control: Controlling delivery speed helps to ensure more accuracy in pronunciation including specific words. Use prompts to call out pacing and target words so the model stays consistent without SSML like Speaking Slowly,Short Pause\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"Tell the story as an enthusiastic tour guide.\"\n",
    "TEXT = (\n",
    "    \"[cheerful] We arrived at the plaza just as the bells rang. \"\n",
    "    \"[switch to a hushed Spanish accent] Escucha, the city whispers its secrets at dusk. \"\n",
    "    \"[delighted] Then everyone burst into applause!\"\n",
    ")\n",
    "file_dynamic = generate_tts_audio(client, voice, TEXT, PROMPT, audio_format=\"mp3\", output_file=\"gemini52\")\n",
    "\n",
    "PROMPT = \"Tell the story as an enthusiastic tour guide.\"\n",
    "TEXT = (\n",
    "    \"[cheerful slow pace ] We arrived at the plaza just as the bells rang. \"\n",
    "    \"[switch to a hushed Spanish accent] Escucha, the city whispers its secrets at dusk. \"\n",
    "    \"[delighted fast pace] Then everyone burst into applause!\"\n",
    ")\n",
    "\n",
    "file_pace = generate_tts_audio(client, voice, TEXT, PROMPT, audio_format=\"mp3\", output_file=\"gemini53\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawbacks or issues \n",
    "\n",
    "Even with the expanded controls, a few behaviors require extra guardrails:\n",
    "\n",
    "- **Prompt fidelity**: Dense prompts that mix multiple stylistic constraints can cause Gemini to ignore one instruction entirely (for example dropping an accent change). Iteratively trim prompts and test short snippets before rendering long passages.\n",
    "- **Temperature variance**: Raising `speech_config.temperature` injects creativity but may add filler words, unexpected pauses, or exaggerated pitch arcs. Pull the temperature toward 0.2–0.3 when you need precise corporate narration.\n",
    "- **Emotion/Accent persistence**: Inline cues such as `[whispers]` or `[switch to spanish accent]` sometimes bleed into subsequent sentences. Split the script into multiple synthesis calls if you need hard boundaries.\n",
    "\n",
    "\n",
    "# Where to Go Next\n",
    "\n",
    "- Layer SSML `<say-as>`, `<break>`, or `<emphasis>` tags inside the `parts` array to control pronunciation and pacing without touching your product copy.  \n",
    "- Creating Long Form Audios \n",
    "- use device profiles for generated audios \n",
    "- Streaming speech synthesis \n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Gemini-TTS compresses a lot of capability into a single API: unified credential flow, granular model tiers, flexible audio encodings, and prompt-driven expressiveness. Once your service account is set up and the `generate_tts_audio` function is in place, you can iterate on voice, style, and pacing as easily as editing text.\n",
    "\n",
    "Whether you are shipping a conversational agent, narrating tutorials, or prototyping sonic branding, the same stack scales from quick notebook experiments to production pipelines on Vertex AI.\n",
    "\n",
    "If you enjoyed this article, consider following my profile and signing up for the newsletter to get more insights on cutting-edge AI tools like Gemini-TTS. Have thoughts or questions? Share them in the comments below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
