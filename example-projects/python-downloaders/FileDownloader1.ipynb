{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25daf5c7",
   "metadata": {},
   "source": [
    "\n",
    "# High-Performance File Downloads in Python with PycURL\n",
    "\n",
    "\n",
    "Have you ever needed to download massive datasets, model checkpoints, or other large files in your Python projects—and wished for a tool that’s both fast and reliable . In this post, I’ll show you how to harness the power of **PycURL** for high-performance, robust file downloads. We’ll build a reusable download class that:\n",
    "\n",
    "- Handles chunked downloads for efficiency\n",
    "- Validates file size and MD5 checksums to ensure data integrity\n",
    "- Skips unnecessary downloads to save bandwidth and time\n",
    "- Provides real-time progress updates via callbacks\n",
    "\n",
    "You’ll have a production-ready solution for your data engineering, machine learning, or automation pipelines. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecf882",
   "metadata": {},
   "source": [
    "## Prerequisites: Installing PycURL\n",
    "\n",
    "Before we get started, make sure you have PycURL installed. Here’s how:\n",
    "\n",
    "```bash\n",
    "pip install pycurl\n",
    "```\n",
    "\n",
    "On macOS or Linux, you may also need the libcurl development headers:\n",
    "\n",
    "```bash\n",
    "brew install curl  # macOS\n",
    "# or\n",
    "sudo apt-get install libcurl4-openssl-dev  # Ubuntu/Debian\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c1c764",
   "metadata": {},
   "source": [
    "## Building a Robust Download Class\n",
    "\n",
    "Let’s architect a Python class that makes file downloads both efficient and bulletproof. Here’s what our class will do:\n",
    "\n",
    "- **Accept** a download directory, chunk size, and an optional progress callback\n",
    "- **Check** if the file already exists and is valid (by size and MD5)\n",
    "- **Download** only if needed, with chunked streaming and progress updates\n",
    "- **Validate** the downloaded file for size and MD5 integrity\n",
    "\n",
    "This approach is perfect for AI workflows, where downloading large, versioned datasets or model weights is common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycurl\n",
    "import hashlib\n",
    "\n",
    "class FileDownloader:\n",
    "\tdef __init__(self, download_dir, chunk_size=8192, callback=None):\n",
    "\t\tself.download_dir = download_dir\n",
    "\t\tself.chunk_size = chunk_size\n",
    "\t\tself.callback = callback\n",
    "\n",
    "\tdef _md5sum(self, file_path):\n",
    "\t\t\"\"\"Compute md5 hash of a file asynchronously.\"\"\"\n",
    "\t\thash_md5 = hashlib.md5()\n",
    "\t\t\n",
    "\t\twith open(file_path, \"rb\") as f:\n",
    "\t\t\twhile True:\n",
    "\t\t\t\tchunk = f.read(self.chunk_size)\n",
    "\t\t\t\tif not chunk:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\thash_md5.update(chunk)\n",
    "\t\treturn hash_md5.hexdigest()\n",
    "\n",
    "\tdef _validate_file(self, file_path, expected_size=None, expected_md5=None):\n",
    "\t\tif not os.path.exists(file_path):\n",
    "\t\t\treturn False\n",
    "\t\tif expected_size is not None and os.path.getsize(file_path) != expected_size:\n",
    "\t\t\treturn False\n",
    "\t\tif expected_md5 is not None:\n",
    "\t\t\tactual_md5 = self._md5sum(file_path)\n",
    "\t\t\tif actual_md5 != expected_md5:\n",
    "\t\t\t\treturn False\n",
    "\t\treturn True\n",
    "\n",
    "\tdef download(self, url, filename, expected_size=None, expected_md5=None):\n",
    "\t\tfile_path = os.path.join(self.download_dir, filename)\n",
    "\n",
    "\t\t# Check if file already exists and is valid\n",
    "\t\tif self._validate_file(file_path, expected_size, expected_md5):\n",
    "\t\t\tprint(f\"File {file_path} already exists and is valid. Skipping download.\")\n",
    "\t\t\treturn file_path\n",
    "\n",
    "\t\tmd5 = hashlib.md5()\n",
    "\t\treceived = 0\n",
    "\n",
    "\t\t# Try to get total bytes from Content-Length header\n",
    "\t\ttotal_bytes = None\n",
    "\t\tc = pycurl.Curl()\n",
    "\t\tc.setopt(c.URL, url)\n",
    "\t\tc.setopt(c.NOBODY, 1)\n",
    "\t\tc.perform()\n",
    "\t\ttry:\n",
    "\t\t\ttotal_bytes = int(c.getinfo(pycurl.CONTENT_LENGTH_DOWNLOAD))\n",
    "\t\texcept Exception:\n",
    "\t\t\ttotal_bytes = expected_size\n",
    "\t\tc.close()\n",
    "\n",
    "\t\tdef write_callback(data):\n",
    "\t\t\tnonlocal received\n",
    "\t\t\tf.write(data)\n",
    "\t\t\tmd5.update(data)\n",
    "\t\t\treceived += len(data)\n",
    "\t\t\tif self.callback:\n",
    "\t\t\t\tself.callback(received, total_bytes)\n",
    "\n",
    "\t\twith open(file_path, 'wb') as f:\n",
    "\t\t\tc = pycurl.Curl()\n",
    "\t\t\tc.setopt(c.URL, url)\n",
    "\t\t\tc.setopt(c.WRITEFUNCTION, write_callback)\n",
    "\t\t\tc.perform()\n",
    "\t\t\tc.close()\n",
    "\n",
    "\t\t# Check file size\n",
    "\t\tif expected_size is not None and received != expected_size:\n",
    "\t\t\traise ValueError(f\"Size mismatch: expected {expected_size}, got {received}\")\n",
    "\n",
    "\t\t# Check MD5\n",
    "\t\tif expected_md5 is not None and md5.hexdigest() != expected_md5:\n",
    "\t\t\traise ValueError(\"MD5 checksum mismatch\")\n",
    "\n",
    "\t\treturn file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a66f0",
   "metadata": {},
   "source": [
    "## Usage Example: Downloading with Progress and Validation\n",
    "\n",
    "Here’s how you can use the `FileDownloader` in your own projects:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://dumps.wikimedia.org/enwiki/20250920/enwiki-20250920-pages-articles1.xml-p1p41242.bz2'\n",
    "md5=\"5b594c2af71ecf65505dc42d49ab6121\"\n",
    "size=291274499\n",
    "\n",
    "\n",
    "def progress(bytes_downloaded, total_bytes):\n",
    "\tpercent = (bytes_downloaded / total_bytes) * 100 if total_bytes else 0\n",
    "\tprint(f\"Downloaded {bytes_downloaded}/{total_bytes} bytes ({percent:.2f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "downloader = FileDownloader(download_dir=\"/tmp\", chunk_size=16384, callback=progress)\n",
    "downloader.download(\n",
    "\turl=url,\n",
    "\tfilename=\"largefile.zip\",\n",
    "\texpected_size=size,\n",
    "\texpected_md5=md5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60ae07",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this guide, we explored how to leverage PycURL for high-performance, reliable file downloads in Python.\n",
    "\n",
    "If you found this post helpful, consider subscribing to my newsletter for more deep dives into Python, AI, and engineering best practices. \n",
    "\n",
    "Have questions, feedback, or your own download tips? Drop a comment below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
